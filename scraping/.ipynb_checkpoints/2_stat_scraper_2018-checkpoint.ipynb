{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape Match Data - 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I originally worked on this project, I only scraped data for the regular season of 2018 and part of 2019. The below code finishes scraping for the 2018 post-season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping Imports\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "#SQL Imports\n",
    "import mysql.connector\n",
    "#Pandas imports\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DB Connection\n",
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  passwd=\"\",\n",
    "  database=\"NRL_data\"\n",
    ")\n",
    "mycursor = mydb.cursor(buffered=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all URL's of matches with missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Get all matches\n",
    "all_matches_query = pd.read_sql_query('SELECT id, date, url, home_team_id, away_team_id FROM Matches;', mydb)\n",
    "all_match_df = pd.DataFrame(all_matches_query, columns=['id', 'date', 'url', 'home_team_id', 'away_team_id'])\n",
    "\n",
    "#Find matches that were already scraped\n",
    "already_scraped = 'SELECT DISTINCT match_id FROM PlayerMatchStats;'\n",
    "mycursor.execute(already_scraped,)\n",
    "results = mycursor.fetchall()\n",
    "already_scraped_list = list(map(lambda x: x[0], results))\n",
    "\n",
    "#Remove matches which were already scraped and save remaining match info to not_yet_scraped_df\n",
    "not_yet_scraped = set(list(all_match_df['id'])) - set(already_scraped_list)\n",
    "not_yet_scraped_df = all_match_df[all_match_df['id'].isin(not_yet_scraped)]\n",
    "#print(not_yet_scraped_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate a blank dictionary of matches that need to be scraped by year\n",
    "scraping_dict = {}\n",
    "\n",
    "#Convert 'date' column of not yet_scraped_df to datetime\n",
    "not_yet_scraped_df['date'] = pd.to_datetime(not_yet_scraped_df['date'])\n",
    "\n",
    "#Populate scraping_dict with key = year and values = matches for that year\n",
    "scraping_dict = {}\n",
    "for year in list(not_yet_scraped_df['date'].dt.year.unique()):\n",
    "    scraping_dict[year] = not_yet_scraped_df[not_yet_scraped_df['date'].dt.year == year]\n",
    "\n",
    "#Validate output with 2018 as an example\n",
    "#scraping_dict[2018]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create dictionary to store scraping results\n",
    "player_match_stats = dict.fromkeys(scraping_dict.keys(), {})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create functions to identify team and players by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_team_id(name):\n",
    "    find_team_query = 'SELECT id FROM Teams WHERE nickname = %s;'\n",
    "    mycursor.execute(find_team_query, (name,))\n",
    "    return mycursor.fetchone()[0]\n",
    "\n",
    "def find_or_create_player(first_name, last_name, team_id):\n",
    "    find_player_query = 'SELECT id FROM Players WHERE first_name = %s AND last_name LIKE %s AND current_team = %s LIMIT 1;'\n",
    "    mycursor.execute(find_player_query, (first_name, '%' + last_name + '%', team_id))\n",
    "    result = mycursor.fetchone()\n",
    "    if result is None:\n",
    "        insert_player_query = 'INSERT INTO Players (first_name, last_name, current_team) VALUES (%s, %s, %s);'\n",
    "        data = (first_name, last_name, team_id)\n",
    "        #print(data)\n",
    "        mycursor.execute(insert_player_query, data)\n",
    "        mydb.commit()\n",
    "        result = find_or_create_player(first_name, last_name, team_id)\n",
    "        return int(result)\n",
    "    else:\n",
    "        result = result[0]\n",
    "        #print('id = ' + str(result))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Up WebDriver\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "wait = WebDriverWait(driver, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in [2018]:\n",
    "    year_dict = {}\n",
    "    \n",
    "    #Create a blank list to store URLs where scraping fails\n",
    "    year_dict['errors'] = []\n",
    "    for match in scraping_dict[year].iterrows():\n",
    "        match = match[1]\n",
    "        \n",
    "        #Create match key in the format \"round + home_team + _ + away_team\"\n",
    "        match_key = match['url'].split(str(year) + '/')[1][:-1]\n",
    "        for char in ['-vs-', '-v-', '/', '-']:\n",
    "            match_key = match_key.replace(char, '_')\n",
    "        year_dict[match_key] = {}\n",
    "        \n",
    "        try:\n",
    "            print(match['url'])\n",
    "            \n",
    "            #Use Selenium WebDriver to scrape data and automate the process of flipping through URLs\n",
    "            driver.get(match['url'])\n",
    "            #home_xpath_div = '1', away_xpath_div = '2'\n",
    "            for xpath in ['1', '2']:\n",
    "                wait.until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"player-stats\"]/div[' + xpath + ']/div/div[3]/div/table/tbody')))\n",
    "                for i in range(1, 18):\n",
    "                    name_field = driver.find_element_by_xpath('//*[@id=\"player-stats\"]/div[' + xpath + ']/div/div[3]/div/table/tbody/tr['+ str(i) +']/td[2]/a').get_attribute('innerText').strip()\n",
    "                    first_name = name_field.split(' ')[0].strip().capitalize()\n",
    "                    last_name = name_field.split(' ')[-1].strip().capitalize()\n",
    "                    middle_name = name_field.split(' ')[-2].strip()\n",
    "                    if middle_name.isalpha():\n",
    "                        last_name = middle_name.capitalize() + ' ' + last_name\n",
    "                    if xpath == '1':\n",
    "                        team_id = match['home_team_id']\n",
    "                    elif xpath == '2':\n",
    "                        team_id = match['away_team_id']\n",
    "                    full_name = first_name + '_' + last_name + '_' + str(team_id)\n",
    "                    player_id = find_or_create_player(first_name, last_name, str(team_id))\n",
    "                    \n",
    "                    player_stat_list = []\n",
    "                    player_stat_list.append(player_id)\n",
    "                    player_stat_list.append(team_id)\n",
    "                    player_stat_list.append(match['id'])\n",
    "                    \n",
    "                    for column in range(3, 67):\n",
    "                        if column in [5, 7, 15, 17, 21, 34, 40, 47, 56, 64]:\n",
    "                            continue\n",
    "                        else:\n",
    "                            stat_field = driver.find_element_by_xpath('//*[@id=\"player-stats\"]/div[' + xpath + ']/div/div[3]/div/table/tbody/tr[' + str(i) + ']/td[' + str(column) + ']')\n",
    "                            player_stat_list.append(stat_field.get_attribute('innerText').strip())\n",
    "                    print(player_stat_list)\n",
    "                    year_dict[match_key][full_name] = player_stat_list\n",
    "        except:\n",
    "            print('error: ' + match['url'])\n",
    "            year_dict['errors'].append(match['url'])\n",
    "        print(year_dict[match_key])\n",
    "    \n",
    "    csv_data = pd.DataFrame.from_dict(year_dict, orient='index').replace('-', 0)\n",
    "    #csv_data = pd.DataFrame.from_dict(year_dict, orient='index', columns=column_names).replace('-', 0)\n",
    "    csv_data = csv_data.replace({pd.np.nan: 0})\n",
    "\n",
    "    #print(csv_data)\n",
    "    #print(year_dict)\n",
    "    player_match_stats[year] = year_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually update error URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get match ids of errored URLs for manual updating\n",
    "errors = player_match_stats[2018]['errors']\n",
    "\n",
    "find_incorrect_url_matches = 'SELECT id, url FROM Matches WHERE url IN {};'.format(tuple(errors))\n",
    "mycursor.execute(find_incorrect_url_matches,)\n",
    "results = mycursor.fetchall()\n",
    "#print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manually update URLs which couldn't be scraped\n",
    "\n",
    "mycursor.executemany(\"UPDATE Matches SET url = %s WHERE id = %s\",\n",
    "                    [(\"https://www.nrl.com/draw/nrl-premiership/2018/finals-week-2/game-1/\", \"466\"),\n",
    "                    (\"https://www.nrl.com/draw/nrl-premiership/2018/finals-week-2/game-12/\", \"467\"),\n",
    "                    (\"https://www.nrl.com/draw/nrl-premiership/2018/finals-week-3/game-1/\", \"468\"),\n",
    "                    (\"https://www.nrl.com/draw/nrl-premiership/2018/finals-week-3/game-12/\", \"469\")])\n",
    "mydb.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove errors from match dictionary\n",
    "player_match_stats[2018].keys()\n",
    "player_match_stats[2018] = player_match_stats[2018].pop('errors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert dictionary into Pandas dataframe for easy manipulation and upload\n",
    "player_match_stats[2018] = year_dict\n",
    "player_match_stats[2018]\n",
    "stats_dict = pd.DataFrame()\n",
    "for match in player_match_stats[2018].keys():\n",
    "    match_df = pd.DataFrame.from_dict(player_match_stats[2018][match], orient='index')\n",
    "    stats_dict = stats_dict.append(match_df)\n",
    "stats_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run scraping code for updated match URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "errored_match_query = pd.read_sql_query('SELECT id, date, url, home_team_id, away_team_id FROM Matches WHERE id IN (466, 467, 468, 469);', mydb)\n",
    "errored_match_df = pd.DataFrame(errored_match_query, columns=['id', 'date', 'url', 'home_team_id', 'away_team_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>url</th>\n",
       "      <th>home_team_id</th>\n",
       "      <th>away_team_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>466</td>\n",
       "      <td>2018-09-14</td>\n",
       "      <td>https://www.nrl.com/draw/nrl-premiership/2018/...</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>467</td>\n",
       "      <td>2018-09-15</td>\n",
       "      <td>https://www.nrl.com/draw/nrl-premiership/2018/...</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>468</td>\n",
       "      <td>2018-09-21</td>\n",
       "      <td>https://www.nrl.com/draw/nrl-premiership/2018/...</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>469</td>\n",
       "      <td>2018-09-22</td>\n",
       "      <td>https://www.nrl.com/draw/nrl-premiership/2018/...</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id        date                                                url  \\\n",
       "0  466  2018-09-14  https://www.nrl.com/draw/nrl-premiership/2018/...   \n",
       "1  467  2018-09-15  https://www.nrl.com/draw/nrl-premiership/2018/...   \n",
       "2  468  2018-09-21  https://www.nrl.com/draw/nrl-premiership/2018/...   \n",
       "3  469  2018-09-22  https://www.nrl.com/draw/nrl-premiership/2018/...   \n",
       "\n",
       "   home_team_id  away_team_id  \n",
       "0             4            12  \n",
       "1            13            14  \n",
       "2             7             4  \n",
       "3            15            13  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errored_match_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.nrl.com/draw/nrl-premiership/2018/finals-week-1/broncos-vs-dragons/\n"
     ]
    }
   ],
   "source": [
    "#Re-run scraping query and append results to the DataFrame used to upload data\n",
    "\n",
    "errored_match_query = pd.read_sql_query('SELECT id, date, url, home_team_id, away_team_id FROM Matches WHERE id = 465;', mydb)\n",
    "errored_match_df = pd.DataFrame(errored_match_query, columns=['id', 'date', 'url', 'home_team_id', 'away_team_id'])\n",
    "for match in errored_match_df.iterrows():\n",
    "        match = match[1]\n",
    "        match_key = match['url'].split(str(year) + '/')[1][:-1]\n",
    "        for char in ['-vs-', '-v-', '/', '-']:\n",
    "            match_key = match_key.replace(char, '_')\n",
    "        year_dict[match_key] = {}\n",
    "        \n",
    "        try:\n",
    "            print(match['url'])\n",
    "            driver.get(match['url'])\n",
    "            #home_xpath_div = '1', away_xpath_div = '2'\n",
    "            for xpath in ['1', '2']:\n",
    "                wait.until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"player-stats\"]/div[' + xpath + ']/div/div[3]/div/table/tbody')))\n",
    "                for i in range(1, 18):\n",
    "                    name_field = driver.find_element_by_xpath('//*[@id=\"player-stats\"]/div[' + xpath + ']/div/div[3]/div/table/tbody/tr['+ str(i) +']/td[2]/a').get_attribute('innerText').strip()\n",
    "                    first_name = name_field.split(' ')[0].strip().capitalize()\n",
    "                    last_name = name_field.split(' ')[-1].strip().capitalize()\n",
    "                    middle_name = name_field.split(' ')[-2].strip()\n",
    "                    if middle_name.isalpha():\n",
    "                        last_name = middle_name.capitalize() + ' ' + last_name\n",
    "                    if xpath == '1':\n",
    "                        team_id = match['home_team_id']\n",
    "                    elif xpath == '2':\n",
    "                        team_id = match['away_team_id']\n",
    "                    full_name = first_name + '_' + last_name + '_' + str(team_id)\n",
    "                    player_id = find_or_create_player(first_name, last_name, str(team_id))\n",
    "                    \n",
    "                    player_stat_list = []\n",
    "                    player_stat_list.append(player_id)\n",
    "                    player_stat_list.append(team_id)\n",
    "                    player_stat_list.append(match['id'])\n",
    "                    \n",
    "                    for column in range(3, 67):\n",
    "                        if column in [5, 7, 15, 17, 21, 34, 40, 47, 56, 64]:\n",
    "                            continue\n",
    "                        else:\n",
    "                            stat_field = driver.find_element_by_xpath('//*[@id=\"player-stats\"]/div[' + xpath + ']/div/div[3]/div/table/tbody/tr[' + str(i) + ']/td[' + str(column) + ']')\n",
    "                            player_stat_list.append(stat_field.get_attribute('innerText').strip())\n",
    "                    print(player_stat_list)\n",
    "                    year_dict[match_key][full_name] = player_stat_list\n",
    "        except:\n",
    "            #print('error: ' + match['url'])\n",
    "            year_dict['errors'].append(match['url'])\n",
    "        #print(year_dict[match_key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_match_stats[2018] = year_dict\n",
    "player_match_stats[2018]\n",
    "stats_dict = pd.DataFrame()\n",
    "for match in player_match_stats[2018].keys():\n",
    "    match_df = pd.DataFrame.from_dict(player_match_stats[2018][match], orient='index')\n",
    "    stats_dict = stats_dict.append(match_df)\n",
    "#stats_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update column names\n",
    "column_names = ['player_id', 'team_id', 'match_id', 'number', 'position', 'minutes_played', 'points', 'tries',\n",
    "                'conversions','conversion_attempts', 'penalty_goals', 'conversion_percentage','field_goals',\n",
    "                'fantasy_points', 'total_runs', 'total_run_metres', 'kick_return_metres', 'post_contact_metres',\n",
    "                'line_breaks', 'line_break_assists', 'try_assists', 'line_engaged_runs', 'tackle_breaks', 'hit_ups',\n",
    "                'play_the_ball', 'average_play_the_ball_seconds', 'dummy_half_runs', 'dummy_half_run_metres', \n",
    "                'steals', 'offloads', 'dummy_passes', 'passes', 'receipts', 'pass_to_run_ratio', 'tackle_percentage',\n",
    "                'tackles_made', 'tackles_missed', 'ineffective_tackles', 'intercepts', 'kicks_defused', 'kicks',\n",
    "                'kicking_metres', 'forced_drop_outs', 'bomb_kicks', 'grubbers', 'fourty_twenty',\n",
    "                'cross_field_kicks', 'kicked_dead', 'errors', 'handling_errors', 'one_on_ones_lost', 'penalties',\n",
    "                'on_report', 'sin_bins', 'send_offs', 'stint_one', 'stint_two']\n",
    "\n",
    "player_match_stats[2018] = year_dict\n",
    "player_match_stats[2018]\n",
    "year_df = pd.DataFrame()\n",
    "\n",
    "#Export final results to CSV for insertion to db\n",
    "for match in player_match_stats[2018].keys():\n",
    "    match_df = pd.DataFrame.from_dict(player_match_stats[2018][match], orient='index', columns=column_names).reset_index()\n",
    "    year_df = year_df.append(match_df, ignore_index = True)\n",
    "year_df = year_df.replace('-', 0).replace({pd.np.nan: 0})\n",
    "#year_df\n",
    "year_df.to_csv('./csv_files/' + str(year) + '_data.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mycursor.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
